{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. INSERT DATA INTO MONGO DB\n",
    "## Converting the raw data into a JSON format and then inserting it into the MongoDB database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the script\n",
      "mongodb+srv://nimishkumar0305:nimish0305@pinewheel.jtw34.mongodb.net/?retryWrites=true&w=majority&appName=pinewheel\n",
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "print(\"Starting the script\")\n",
    "env_path = Path('.env')\n",
    "load_dotenv()\n",
    "uri = os.getenv(\"MONGO_URI\")\n",
    "print(uri)\n",
    "\n",
    "\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client[\"pinewheel\"]\n",
    "collection = db[\"network_scans\"] \n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "    \n",
    "    # Load my JSON data\n",
    "    with open('data.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_one(data)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BUILD A GRAPH FROM MONGO DB\n",
    "## Creating a graph from the data in MongoDB and then storing it in a ChromaDB Vector database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'chromadb' has no attribute 'embedding_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Initialize Chroma DB client\u001b[39;00m\n\u001b[1;32m     26\u001b[0m client_chroma \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m     27\u001b[0m collection_chroma \u001b[38;5;241m=\u001b[39m client_chroma\u001b[38;5;241m.\u001b[39mget_or_create_collection(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscan_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m---> 29\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39m\u001b[43mchromadb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_functions\u001b[49m\u001b[38;5;241m.\u001b[39mSklearnEmbeddingFunction(svd, vectorizer)\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Initialize TF-IDF Vectorizer\u001b[39;00m\n\u001b[1;32m     34\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'chromadb' has no attribute 'embedding_functions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "env_path = Path('.env')\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB URI from .env\n",
    "uri = os.getenv(\"MONGO_URI\")\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client[\"pinewheel\"]\n",
    "collection = db[\"network_scans\"]\n",
    "\n",
    "# Initialize Chroma DB client\n",
    "client_chroma = chromadb.Client()\n",
    "collection_chroma = client_chroma.get_or_create_collection(\n",
    "    \"scan_graph\", \n",
    "    embedding_function=chromadb.embedding_functions.SklearnEmbeddingFunction(svd, vectorizer)\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Example corpus to fit the vectorizer (e.g., text from your graph nodes)\n",
    "sample_corpus = [\n",
    "    \"New scan report detected.\",\n",
    "    \"Nmap scan results indicate open ports.\",\n",
    "    \"FFUF scan identified hidden directories.\",\n",
    "    \"Network vulnerability detected in scan.\"\n",
    "]\n",
    "# Fit the vectorizer on the corpus\n",
    "vectorizer.fit(sample_corpus)  # Fitting the vectorizer\n",
    "\n",
    "# Initialize TruncatedSVD\n",
    "num_features = len(vectorizer.get_feature_names_out())\n",
    "n_components = min(300, num_features)\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the SVD model with the entire TF-IDF matrix\n",
    "tfidf_matrix = vectorizer.transform(sample_corpus)  # Transform the sample corpus\n",
    "svd.fit(tfidf_matrix)  # Fit SVD on the transformed TF-IDF matrix\n",
    "\n",
    "# Initialize NetworkX graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Rate limit parameters for the Free Plan\n",
    "MAX_RPM = 3  # Requests per minute\n",
    "request_counter = 0\n",
    "last_request_time = time.time()\n",
    "\n",
    "# Helper function to manage rate limits\n",
    "def rate_limit_guard():\n",
    "    global request_counter, last_request_time\n",
    "    current_time = time.time()\n",
    "    time_diff = current_time - last_request_time\n",
    "\n",
    "    if time_diff < 60:\n",
    "        if request_counter >= MAX_RPM:\n",
    "            time_to_wait = 60 - time_diff\n",
    "            print(f\"Rate limit hit. Sleeping for {time_to_wait:.2f} seconds...\")\n",
    "            time.sleep(time_to_wait)\n",
    "            request_counter = 0\n",
    "\n",
    "    request_counter += 1\n",
    "    last_request_time = current_time\n",
    "\n",
    "# Helper function to get text embeddings using TF-IDF and SVD\n",
    "def get_text_embedding(text):\n",
    "    rate_limit_guard()\n",
    "    \n",
    "    # Transform the text using the fitted TF-IDF vectorizer\n",
    "    tfidf_matrix = vectorizer.transform([text])\n",
    "    \n",
    "    # Transform the TF-IDF matrix using the already fitted SVD model\n",
    "    embedding = svd.transform(tfidf_matrix)  # Apply the fitted SVD to reduce dimensionality\n",
    "    \n",
    "    # Flatten the 2D array to a 1D array for storage\n",
    "    return embedding.flatten()\n",
    "\n",
    "# Graph and MongoDB data ingestion functions remain unchanged\n",
    "def add_or_update_node(graph, node_data):\n",
    "    node_id = node_data.get(\"host\") or node_data.get(\"url\")\n",
    "    if graph.has_node(node_id):\n",
    "        print(f\"Node {node_id} exists, updating...\")\n",
    "        graph.nodes[node_id].update(node_data)\n",
    "    else:\n",
    "        print(f\"Node {node_id} does not exist, creating...\")\n",
    "        graph.add_node(node_id, **node_data)\n",
    "\n",
    "def add_or_update_edge(graph, node1, node2, edge_data):\n",
    "    if graph.has_edge(node1, node2):\n",
    "        print(f\"Edge between {node1} and {node2} exists, updating...\")\n",
    "        graph[node1][node2].update(edge_data)\n",
    "    else:\n",
    "        print(f\"Edge between {node1} and {node2} does not exist, creating...\")\n",
    "        graph.add_edge(node1, node2, **edge_data)\n",
    "\n",
    "def ingest_data_from_mongo():\n",
    "    scans = collection.find()\n",
    "    for scan in scans:\n",
    "        if \"nmap_scan_1\" in scan:\n",
    "            nmap_data = scan[\"nmap_scan_1\"]\n",
    "            add_or_update_node(graph, {\n",
    "                \"host\": nmap_data[\"host\"],\n",
    "                \"status\": nmap_data[\"status\"],\n",
    "                \"latency\": nmap_data[\"latency\"],\n",
    "                \"ports\": nmap_data[\"ports\"]\n",
    "            })\n",
    "            for port in nmap_data[\"ports\"]:\n",
    "                add_or_update_edge(graph, nmap_data[\"host\"], port[\"port\"], {\n",
    "                    \"protocol\": port[\"protocol\"],\n",
    "                    \"state\": port[\"state\"],\n",
    "                    \"service\": port[\"service\"]\n",
    "                })\n",
    "        \n",
    "        if \"ffuf_scan\" in scan:\n",
    "            ffuf_data = scan[\"ffuf_scan\"]\n",
    "            add_or_update_node(graph, {\n",
    "                \"url\": ffuf_data[\"url\"],\n",
    "                \"status_filter\": ffuf_data[\"status_filter\"],\n",
    "                \"results\": ffuf_data[\"results\"]\n",
    "            })\n",
    "            for result in ffuf_data[\"results\"]:\n",
    "                add_or_update_edge(graph, ffuf_data[\"url\"], result[\"url\"], {\n",
    "                    \"status\": result[\"status\"],\n",
    "                    \"size\": result[\"size\"],\n",
    "                    \"duration\": result[\"duration\"]\n",
    "                })\n",
    "\n",
    "def handle_text_data(text):\n",
    "    # Get the text embedding\n",
    "    embedding = get_text_embedding(text)\n",
    "    \n",
    "    # Store the text node in Chroma DB\n",
    "    collection_chroma.add(\n",
    "        ids=[text],  # Pass the `id` as a separate string argument\n",
    "        embeddings=[embedding],  # Pass the embedding as a list\n",
    "        metadatas=[{\"text\": text}]  # Metadata should be in a list\n",
    "    )\n",
    "    \n",
    "    # Return stored text data for graph usage\n",
    "    return {\"text\": text, \"embedding\": embedding}\n",
    "\n",
    "def check_and_update_existing_nodes(new_data, node_id):\n",
    "    if node_id in graph:\n",
    "        existing_node_data = graph.nodes[node_id]\n",
    "        for key, value in new_data.items():\n",
    "            if key not in existing_node_data or existing_node_data[key] != value:\n",
    "                existing_node_data[key] = value\n",
    "        print(f\"Node {node_id} updated.\")\n",
    "    else:\n",
    "        graph.add_node(node_id, **new_data)\n",
    "        print(f\"Node {node_id} added.\")\n",
    "\n",
    "def update_graph_with_new_data(scan_data):\n",
    "    for scan in scan_data:\n",
    "        if \"nmap_scan_1\" in scan:\n",
    "            nmap_data = scan[\"nmap_scan_1\"]\n",
    "            node_id = nmap_data[\"host\"]\n",
    "            new_data = {\n",
    "                \"status\": nmap_data[\"status\"],\n",
    "                \"latency\": nmap_data[\"latency\"],\n",
    "                \"ports\": nmap_data[\"ports\"]\n",
    "            }\n",
    "            check_and_update_existing_nodes(new_data, node_id)\n",
    "\n",
    "def build_and_update_graph():\n",
    "    ingest_data_from_mongo()\n",
    "    text_data = handle_text_data(\"New scan report detected\")\n",
    "    scan_data = [\n",
    "        {\"nmap_scan_1\": {\"host\": \"10.10.10.1\", \"status\": \"up\", \"latency\": 20, \"ports\": [{\"port\": 80, \"protocol\": \"tcp\", \"state\": \"open\", \"service\": \"http\"}]}},\n",
    "        {\"ffuf_scan\": {\"url\": \"http://example.com\", \"status_filter\": \"200\", \"results\": [{\"url\": \"/admin\", \"status\": 200, \"size\": 512, \"duration\": 1.5}]}}\n",
    "    ]\n",
    "    update_graph_with_new_data(scan_data)\n",
    "\n",
    "# Execute graph build and update process\n",
    "build_and_update_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING GRAPH TO MongoDB\n",
    "## Store nodes in a nodes collection and edges in an edges collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections: ['network_scans']\n"
     ]
    }
   ],
   "source": [
    "node_collection = db[\"graph_nodes\"]  # Collection for nodes\n",
    "edge_collection = db[\"graph_edges\"]  # Collection for edges\n",
    "\n",
    "# Check if collections are created\n",
    "print(\"Available collections:\", db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved to MongoDB\n",
      "SAVED GRAPH TO MONGO\n"
     ]
    }
   ],
   "source": [
    "# Saving the graph nodes and edges to MongoDB\n",
    "def save_graph_to_mongo():\n",
    "    for node_id, node_data in graph.nodes(data=True):\n",
    "        node_collection.update_one(\n",
    "            {\"node_id\": node_id},  # Use node_id as a unique identifier\n",
    "            {\"$set\": {\"node_id\": node_id, **node_data}},  # Save the node's data\n",
    "            upsert=True  # If node doesn't exist, insert it\n",
    "        )\n",
    "    \n",
    "    for node1, node2, edge_data in graph.edges(data=True):\n",
    "        edge_collection.update_one(\n",
    "            {\"source\": node1, \"target\": node2},  # Use source and target as identifiers\n",
    "            {\"$set\": {\"source\": node1, \"target\": node2, **edge_data}},  # Save the edge's data\n",
    "            upsert=True  # If edge doesn't exist, insert it\n",
    "        )\n",
    "    print(\"Graph saved to MongoDB\")\n",
    "\n",
    "# Save the graph to MongoDB\n",
    "save_graph_to_mongo()\n",
    "print(\"SAVED GRAPH TO MONGO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in MongoDB:\n",
      "{'_id': ObjectId('673362f400d1c230affbf3b6'), 'node_id': '10.10.11.248', 'host': '10.10.11.248', 'latency': '0.057s', 'ports': [{'port': 22, 'protocol': 'tcp', 'state': 'open', 'service': 'ssh', 'reason': 'syn-ack'}, {'port': 80, 'protocol': 'tcp', 'state': 'open', 'service': 'http', 'reason': 'syn-ack'}, {'port': 389, 'protocol': 'tcp', 'state': 'open', 'service': 'ldap', 'reason': 'syn-ack'}, {'port': 443, 'protocol': 'tcp', 'state': 'open', 'service': 'https', 'reason': 'syn-ack'}, {'port': 5667, 'protocol': 'tcp', 'state': 'open', 'service': 'unknown', 'reason': 'syn-ack'}], 'status': 'up'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf3fc'), 'node_id': 22}\n",
      "{'_id': ObjectId('673362f400d1c230affbf48c'), 'node_id': 80}\n",
      "{'_id': ObjectId('673362f400d1c230affbf4bc'), 'node_id': 389}\n",
      "{'_id': ObjectId('673362f400d1c230affbf4ea'), 'node_id': 443}\n",
      "{'_id': ObjectId('673362f400d1c230affbf503'), 'node_id': 5667}\n",
      "{'_id': ObjectId('673362f400d1c230affbf510'), 'node_id': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'results': [{'url': 'images', 'status': 301, 'size': 340, 'duration': '48ms'}, {'url': 'index.php', 'status': 302, 'size': 27, 'duration': '81ms'}, {'url': 'about', 'status': 301, 'size': 339, 'duration': '46ms'}, {'url': 'login.php', 'status': 200, 'size': 26575, 'duration': '96ms'}, {'url': 'help', 'status': 301, 'size': 338, 'duration': '45ms'}, {'url': 'tools', 'status': 301, 'size': 339, 'duration': '44ms'}, {'url': 'mobile', 'status': 301, 'size': 340, 'duration': '43ms'}, {'url': 'admin', 'status': 301, 'size': 339, 'duration': '43ms'}, {'url': 'reports', 'status': 301, 'size': 341, 'duration': '43ms'}, {'url': 'account', 'status': 301, 'size': 341, 'duration': '52ms'}, {'url': 'includes', 'status': 301, 'size': 342, 'duration': '45ms'}, {'url': 'install.php', 'status': 302, 'size': 0, 'duration': '82ms'}, {'url': 'backend', 'status': 301, 'size': 341, 'duration': '45ms'}, {'url': 'db', 'status': 301, 'size': 336, 'duration': '51ms'}, {'url': 'api', 'status': 301, 'size': 337, 'duration': '90ms'}, {'url': 'upgrade.php', 'status': 302, 'size': 0, 'duration': '99ms'}, {'url': 'config', 'status': 301, 'size': 340, 'duration': '57ms'}, {'url': 'suggest.php', 'status': 200, 'size': 27, 'duration': '100ms'}, {'url': 'views', 'status': 301, 'size': 339, 'duration': '51ms'}, {'url': 'sounds', 'status': 403, 'size': 286, 'duration': '45ms'}, {'url': 'rr.php', 'status': 302, 'size': 0, 'duration': '154ms'}, {'url': 'terminal', 'status': 200, 'size': 5215, 'duration': '159ms'}, {'url': '.php', 'status': 403, 'size': 286, 'duration': '45ms'}, {'url': '.html', 'status': 403, 'size': 286, 'duration': '47ms'}], 'status_filter': '404', 'url': 'https://nagios.monitored.htb/nagiosxi/FUZZ'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf521'), 'node_id': 'images'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf52f'), 'node_id': 'index.php'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf53d'), 'node_id': 'about'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf551'), 'node_id': 'login.php'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf55e'), 'node_id': 'help'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf56c'), 'node_id': 'tools'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf583'), 'node_id': 'mobile'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf594'), 'node_id': 'admin'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf5a8'), 'node_id': 'reports'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf5b4'), 'node_id': 'account'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf5c3'), 'node_id': 'includes'}\n",
      "{'_id': ObjectId('673362f400d1c230affbf5d3'), 'node_id': 'install.php'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf5e9'), 'node_id': 'backend'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf609'), 'node_id': 'db'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf621'), 'node_id': 'api'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf63f'), 'node_id': 'upgrade.php'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf65b'), 'node_id': 'config'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf672'), 'node_id': 'suggest.php'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf680'), 'node_id': 'views'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf68d'), 'node_id': 'sounds'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf6b0'), 'node_id': 'rr.php'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf735'), 'node_id': 'terminal'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf78a'), 'node_id': '.php'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf7c6'), 'node_id': '.html'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf7e1'), 'node_id': '10.10.10.1', 'latency': 20, 'ports': [{'port': 80, 'protocol': 'tcp', 'state': 'open', 'service': 'http'}], 'status': 'up'}\n",
      "\n",
      "Edges in MongoDB:\n",
      "{'_id': ObjectId('673362f500d1c230affbf7fe'), 'target': 22, 'source': '10.10.11.248', 'protocol': 'tcp', 'service': 'ssh', 'state': 'open'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf81a'), 'target': 80, 'source': '10.10.11.248', 'protocol': 'tcp', 'service': 'http', 'state': 'open'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf830'), 'source': '10.10.11.248', 'target': 389, 'protocol': 'tcp', 'service': 'ldap', 'state': 'open'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf841'), 'source': '10.10.11.248', 'target': 443, 'protocol': 'tcp', 'service': 'https', 'state': 'open'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf84d'), 'source': '10.10.11.248', 'target': 5667, 'protocol': 'tcp', 'service': 'unknown', 'state': 'open'}\n",
      "{'_id': ObjectId('673362f500d1c230affbf85d'), 'target': 'images', 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'duration': '48ms', 'size': 340, 'status': 301}\n",
      "{'_id': ObjectId('673362f500d1c230affbf874'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'index.php', 'duration': '81ms', 'size': 27, 'status': 302}\n",
      "{'_id': ObjectId('673362f500d1c230affbf891'), 'target': 'about', 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'duration': '46ms', 'size': 339, 'status': 301}\n",
      "{'_id': ObjectId('673362f500d1c230affbf8a2'), 'target': 'login.php', 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'duration': '96ms', 'size': 26575, 'status': 200}\n",
      "{'_id': ObjectId('673362f500d1c230affbf8b2'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'help', 'duration': '45ms', 'size': 338, 'status': 301}\n",
      "{'_id': ObjectId('673362f500d1c230affbf8c3'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'tools', 'duration': '44ms', 'size': 339, 'status': 301}\n",
      "{'_id': ObjectId('673362f500d1c230affbf8ce'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'mobile', 'duration': '43ms', 'size': 340, 'status': 301}\n",
      "{'_id': ObjectId('673362f500d1c230affbf8f0'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'admin', 'duration': '43ms', 'size': 339, 'status': 301}\n",
      "{'_id': ObjectId('673362f600d1c230affbf911'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'reports', 'duration': '43ms', 'size': 341, 'status': 301}\n",
      "{'_id': ObjectId('673362f600d1c230affbf926'), 'target': 'account', 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'duration': '52ms', 'size': 341, 'status': 301}\n",
      "{'_id': ObjectId('673362f600d1c230affbf942'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'includes', 'duration': '45ms', 'size': 342, 'status': 301}\n",
      "{'_id': ObjectId('673362f600d1c230affbf954'), 'target': 'install.php', 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'duration': '82ms', 'size': 0, 'status': 302}\n",
      "{'_id': ObjectId('673362f600d1c230affbf96c'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'backend', 'duration': '45ms', 'size': 341, 'status': 301}\n",
      "{'_id': ObjectId('673362f600d1c230affbf97c'), 'target': 'db', 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'duration': '51ms', 'size': 336, 'status': 301}\n",
      "{'_id': ObjectId('673362f600d1c230affbf987'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'api', 'duration': '90ms', 'size': 337, 'status': 301}\n",
      "{'_id': ObjectId('673362f600d1c230affbf9ac'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'upgrade.php', 'duration': '99ms', 'size': 0, 'status': 302}\n",
      "{'_id': ObjectId('673362f600d1c230affbfa30'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'config', 'duration': '57ms', 'size': 340, 'status': 301}\n",
      "{'_id': ObjectId('673362f600d1c230affbfa75'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'suggest.php', 'duration': '100ms', 'size': 27, 'status': 200}\n",
      "{'_id': ObjectId('673362f600d1c230affbfa91'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'views', 'duration': '51ms', 'size': 339, 'status': 301}\n",
      "{'_id': ObjectId('673362f600d1c230affbfaab'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'sounds', 'duration': '45ms', 'size': 286, 'status': 403}\n",
      "{'_id': ObjectId('673362f600d1c230affbfab7'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'rr.php', 'duration': '154ms', 'size': 0, 'status': 302}\n",
      "{'_id': ObjectId('673362f600d1c230affbfac5'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': 'terminal', 'duration': '159ms', 'size': 5215, 'status': 200}\n",
      "{'_id': ObjectId('673362f600d1c230affbfad8'), 'target': '.php', 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'duration': '45ms', 'size': 286, 'status': 403}\n",
      "{'_id': ObjectId('673362f600d1c230affbfae6'), 'source': 'https://nagios.monitored.htb/nagiosxi/FUZZ', 'target': '.html', 'duration': '47ms', 'size': 286, 'status': 403}\n"
     ]
    }
   ],
   "source": [
    "# Verifying the saved nodes and edges in MongoDB\n",
    "def verify_saved_graph():\n",
    "    # Fetch all nodes from MongoDB\n",
    "    nodes = node_collection.find()\n",
    "    print(\"Nodes in MongoDB:\")\n",
    "    for node in nodes:\n",
    "        print(node)\n",
    "\n",
    "    # Fetch all edges from MongoDB\n",
    "    edges = edge_collection.find()\n",
    "    print(\"\\nEdges in MongoDB:\")\n",
    "    for edge in edges:\n",
    "        print(edge)\n",
    "\n",
    "# Verify the saved graph\n",
    "verify_saved_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD GRAPH FROM MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded from MongoDB\n"
     ]
    }
   ],
   "source": [
    "# Loading the graph from MongoDB\n",
    "def load_graph_from_mongo():\n",
    "    # Initialize a new NetworkX graph\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    # Load nodes from MongoDB\n",
    "    nodes = node_collection.find()\n",
    "    for node in nodes:\n",
    "        graph.add_node(node['node_id'], **{key: value for key, value in node.items() if key != 'node_id'})\n",
    "    \n",
    "    # Load edges from MongoDB\n",
    "    edges = edge_collection.find()\n",
    "    for edge in edges:\n",
    "        graph.add_edge(edge['source'], edge['target'], **{key: value for key, value in edge.items() if key not in ['source', 'target']})\n",
    "    \n",
    "    print(\"Graph loaded from MongoDB\")\n",
    "    return graph\n",
    "\n",
    "# Example usage to load graph from MongoDB\n",
    "graph = load_graph_from_mongo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE PIPELINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Node 10.10.11.248: tcp port 22 (state: open), tcp port 80 (state: open) Node 22: tcp port 22 (state: open) Node 80: tcp port 80 (state: open)\n",
      "Inference Time: 0.0024 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import chromadb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# Initialize Chroma DB client\n",
    "client_chroma = chromadb.Client()\n",
    "collection_chroma = client_chroma.get_collection(\"scan_graph\")\n",
    "\n",
    "# Initialize NetworkX graph (assuming you've already created this earlier)\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Function to fit the vectorizer on a corpus (or graph nodes' text data)\n",
    "def fit_vectorizer_on_corpus(corpus):\n",
    "    vectorizer.fit(corpus)\n",
    "\n",
    "# Function to embed text data using TF-IDF\n",
    "def get_text_embedding(text):\n",
    "    # Transform the text using TF-IDF vectorizer\n",
    "    return vectorizer.transform([text]).toarray()\n",
    "\n",
    "# Function to create a text representation for each node\n",
    "def create_node_text_representation(node):\n",
    "    # Combine node_id and port info into a single string for the node\n",
    "    node_id = node.get(\"node_id\", \"\")\n",
    "    ports = node.get(\"ports\", [])\n",
    "    port_info = \", \".join([f\"{port['protocol']} port {port['port']} (state: {port['state']})\" for port in ports])\n",
    "    \n",
    "    # Create a text representation by combining node_id and port info\n",
    "    return f\"Node {node_id}: {port_info}\"\n",
    "\n",
    "# Function to extract relevant context from the graph based on cosine similarity\n",
    "def extract_relevant_context(query, top_n=3):\n",
    "    # Embed the query using TF-IDF\n",
    "    query_embedding = get_text_embedding(query)\n",
    "\n",
    "    # Get embeddings of all nodes in the graph (we assume node data contains text)\n",
    "    node_embeddings = {}\n",
    "    for node in graph.nodes(data=True):\n",
    "        node_text = create_node_text_representation(node[1])  # Create text from node attributes\n",
    "        node_embeddings[node[0]] = get_text_embedding(node_text)\n",
    "\n",
    "    # Calculate cosine similarities between the query and each node's text embedding\n",
    "    similarities = {}\n",
    "    for node_id, embedding in node_embeddings.items():\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities[node_id] = similarity[0][0]\n",
    "\n",
    "    # Sort nodes by similarity and pick the top N most similar nodes\n",
    "    top_nodes = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Extract the text of the most similar nodes as the context\n",
    "    context = \" \".join([create_node_text_representation(graph.nodes[node_id]) for node_id, _ in top_nodes])\n",
    "\n",
    "    return context\n",
    "\n",
    "# Function to generate the answer based on the relevant context from the graph\n",
    "def generate_answer_with_graph(query):\n",
    "    # Step 1: Extract relevant context using the graph\n",
    "    context = extract_relevant_context(query)\n",
    "\n",
    "    # Step 2: Use the context to generate an answer\n",
    "    # (In this case, we're just returning the context directly)\n",
    "    answer = context\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Example Query\n",
    "query = \"What ports are open on the target server?\"\n",
    "\n",
    "# Sample corpus of text from which to fit the vectorizer\n",
    "sample_corpus = [\n",
    "    \"New scan report detected.\",\n",
    "    \"Nmap scan results indicate open ports.\",\n",
    "    \"FFUF scan identified hidden directories.\",\n",
    "    \"Network vulnerability detected in scan.\"\n",
    "    # Add more sample text to fit the vectorizer\n",
    "]\n",
    "\n",
    "# Fit the vectorizer on the sample corpus\n",
    "fit_vectorizer_on_corpus(sample_corpus)\n",
    "\n",
    "# Example of adding nodes to the graph with meaningful text data\n",
    "graph.add_node(1, node_id=\"10.10.11.248\", ports=[{'port': 22, 'protocol': 'tcp', 'state': 'open', 'service': 'ssh'}, {'port': 80, 'protocol': 'tcp', 'state': 'open', 'service': 'http'}])\n",
    "graph.add_node(2, node_id=\"22\", ports=[{'port': 22, 'protocol': 'tcp', 'state': 'open', 'service': 'ssh'}])\n",
    "graph.add_node(3, node_id=\"80\", ports=[{'port': 80, 'protocol': 'tcp', 'state': 'open', 'service': 'http'}])\n",
    "graph.add_node(4, node_id=\"443\", ports=[{'port': 443, 'protocol': 'tcp', 'state': 'open', 'service': 'https'}])\n",
    "\n",
    "# Benchmark the time taken to generate an answer\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the answer from the graph-based RAG pipeline\n",
    "answer = generate_answer_with_graph(query)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Time taken for inference\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "# Print results\n",
    "print(f\"Generated Answer: {answer}\")\n",
    "print(f\"Inference Time: {inference_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-rag-system-vx6WuNkf-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
